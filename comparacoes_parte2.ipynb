{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIVERSIDADE DE BRASÍLIA - DEPARTAMENTO DE ESTATÍSTICA\\\n",
    "Elaine de Oliveira\n",
    "## Projeto de Computação Eficiente, parte 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando os arquivos baixados no trabalho anterior, realizo as seguintes manipulações de dados:\n",
    "\n",
    "        1) Carregamento das colunas 'estabelecimento_uf', 'vacina_descricao_dose', 'estabelecimento_municipio_codigo' de todos os arquivos\n",
    "        2) Leitura do csv com os codigos das regiões de saúde\n",
    "        3) Junção das duas tabelas anteriores\n",
    "        4) Contagem da quantidade de vacinados por região \n",
    "        5) Divisão em faixas alta e baixa\n",
    "        6) Visualização das cinco regiões com menos vacinados em cada faixa\n",
    "        7) Retorno da tabela para o python\n",
    "\n",
    "As manipulações serão feitas utilizando novos quatro métodos: **SQLite, MongoDB, Spark e Polars**. Como o SQLite e o MongoDB não possuem funções para leitura de csv nativas, usarei o pyarrow para a leitura dos arquivos neste dois casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura dos arquivos com o pyarrow\n",
    "import pyarrow.dataset as ds\n",
    "from pyarrow import csv\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "\n",
    "dir = 'dados/'\n",
    "dataset = ds.dataset(dir, \n",
    "        format=ds.CsvFileFormat(parse_options=csv.ParseOptions(delimiter=';'), convert_options=csv.ConvertOptions(null_values=['None',''])))\n",
    "vacinas = dataset.scanner(columns=['estabelecimento_uf', 'vacina_descricao_dose', 'estabelecimento_municipio_codigo']).to_batches()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primeiro Método: SQLite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 92.0157 s\n",
      "File: <ipython-input-3-122a11be7eaf>\n",
      "Function: sqlite_func at line 2\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     2                                           def sqlite_func():\n",
      "     3                                               #Conecta ao sqlite\n",
      "     4         1    1266000.0 1266000.0      0.1      con = sqlite3.connect(\"ce_trab2.db\")\n",
      "     5                                           \n",
      "     6                                               #1 Cria tabela vacinas e carrega os dados\n",
      "     7         1    4715749.0 4715749.0      0.5      con.execute('CREATE TABLE vacinas(estabelecimento_uf, vacina_descricao_dose, estabelecimento_municipio_codigo)')\n",
      "     8      8261    4170200.0    504.8      0.5      for i in vacinas:\n",
      "     9      8261  458247196.0  55471.2     49.8          d = i.to_pylist()\n",
      "    10      8261  273624830.0  33122.5     29.7          con.executemany('INSERT INTO vacinas VALUES(:estabelecimento_uf,:vacina_descricao_dose,:estabelecimento_municipio_codigo)',d)\n",
      "    11                                           \n",
      "    12                                               #2 Cria tabela IBGE e carrega os dados\n",
      "    13                                               #colunas do csv ['UF', 'Município', 'Cód IBGE', 'Cód Região de Saúde', 'Nome da Região de Saúde']\n",
      "    14         1    6721892.0 6721892.0      0.7      pd.read_csv('Tabela_codigos.csv', index_col=0).to_sql('ibge', con, index=False)\n",
      "    15                                               \n",
      "    16                                               #3/4 Junta as tabelas e conta vacinados por região de saúde\n",
      "    17         1  163903988.0 163903988.0     17.8      con.execute('''\n",
      "    18                                               CREATE TABLE joined AS\n",
      "    19                                               SELECT ibge.'Cód Região de Saúde', ibge.'Nome da Região de Saúde', ibge.UF, count(*) as count\n",
      "    20                                               FROM vacinas\n",
      "    21                                               LEFT JOIN ibge ON vacinas.'estabelecimento_municipio_codigo' = ibge.'Cód IBGE'\n",
      "    22                                               GROUP BY ibge.'Cód Região de Saúde'\n",
      "    23                                               ORDER BY count DESC\n",
      "    24                                               ''')\n",
      "    25                                           \n",
      "    26                                               #5 Cria as faixas de vacinação\n",
      "    27         1     812000.0 812000.0      0.1      con.execute('ALTER TABLE joined ADD faixa')\n",
      "    28         1    5658897.0 5658897.0      0.6      con.execute(''' \n",
      "    29                                               UPDATE joined\n",
      "    30                                               SET faixa='Baixa' where count < (SELECT MIN(count) from (SELECT * FROM joined LIMIT (SELECT COUNT(*)/2 FROM joined)))\n",
      "    31                                               ''')\n",
      "    32         1       1019.0   1019.0      0.0      con.execute(''' \n",
      "    33                                               UPDATE joined\n",
      "    34                                               SET faixa='Alta' where count >= (SELECT MIN(count) from (SELECT * FROM joined LIMIT (SELECT COUNT(*)/2 FROM joined)))\n",
      "    35                                               ''')\n",
      "    36                                           \n",
      "    37                                               #6 Menos vacinados Alta/Baixa\n",
      "    38         1      15671.0  15671.0      0.0      alta = pd.read_sql_query(\"SELECT * FROM joined WHERE faixa='Alta' ORDER BY count ASC LIMIT 5\", con)\n",
      "    39         1      11997.0  11997.0      0.0      baixa = pd.read_sql_query(\"SELECT * FROM joined WHERE faixa='Baixa' ORDER BY count ASC LIMIT 5\", con)\n",
      "    40                                           \n",
      "    41                                               #7 Retorna tabela para o pandas\n",
      "    42         1      12080.0  12080.0      0.0      df = pd.read_sql_query('SELECT * FROM joined', con)\n",
      "    43                                           \n",
      "    44                                               #Fecha a conexão\n",
      "    45         1     990331.0 990331.0      0.1      con.commit()\n",
      "    46         1       5064.0   5064.0      0.0      con.close()\n",
      "    47                                           \n",
      "    48         1         19.0     19.0      0.0      return df, alta, baixa"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "def sqlite_func():\n",
    "    #Conecta ao sqlite\n",
    "    con = sqlite3.connect(\"ce_trab2.db\")\n",
    "\n",
    "    #1 Cria tabela vacinas e carrega os dados\n",
    "    con.execute('CREATE TABLE vacinas(estabelecimento_uf, vacina_descricao_dose, estabelecimento_municipio_codigo)')\n",
    "    for i in vacinas:\n",
    "        d = i.to_pylist()\n",
    "        con.executemany('INSERT INTO vacinas VALUES(:estabelecimento_uf,:vacina_descricao_dose,:estabelecimento_municipio_codigo)',d)\n",
    "\n",
    "    #2 Cria tabela IBGE e carrega os dados\n",
    "    #colunas do csv ['UF', 'Município', 'Cód IBGE', 'Cód Região de Saúde', 'Nome da Região de Saúde']\n",
    "    pd.read_csv('Tabela_codigos.csv', index_col=0).to_sql('ibge', con, index=False)\n",
    "    \n",
    "    #3/4 Junta as tabelas e conta vacinados por região de saúde\n",
    "    con.execute('''\n",
    "    CREATE TABLE joined AS\n",
    "    SELECT ibge.'Cód Região de Saúde', ibge.'Nome da Região de Saúde', ibge.UF, count(*) as count\n",
    "    FROM vacinas\n",
    "    LEFT JOIN ibge ON vacinas.'estabelecimento_municipio_codigo' = ibge.'Cód IBGE'\n",
    "    GROUP BY ibge.'Cód Região de Saúde'\n",
    "    ORDER BY count DESC\n",
    "    ''')\n",
    "\n",
    "    #5 Cria as faixas de vacinação\n",
    "    con.execute('ALTER TABLE joined ADD faixa')\n",
    "    con.execute(''' \n",
    "    UPDATE joined\n",
    "    SET faixa='Baixa' where count < (SELECT MIN(count) from (SELECT * FROM joined LIMIT (SELECT COUNT(*)/2 FROM joined)))\n",
    "    ''')\n",
    "    con.execute(''' \n",
    "    UPDATE joined\n",
    "    SET faixa='Alta' where count >= (SELECT MIN(count) from (SELECT * FROM joined LIMIT (SELECT COUNT(*)/2 FROM joined)))\n",
    "    ''')\n",
    "\n",
    "    #6 Menos vacinados Alta/Baixa\n",
    "    alta = pd.read_sql_query(\"SELECT * FROM joined WHERE faixa='Alta' ORDER BY count ASC LIMIT 5\", con)\n",
    "    baixa = pd.read_sql_query(\"SELECT * FROM joined WHERE faixa='Baixa' ORDER BY count ASC LIMIT 5\", con)\n",
    "\n",
    "    #7 Retorna tabela para o pandas\n",
    "    df = pd.read_sql_query('SELECT * FROM joined', con)\n",
    "\n",
    "    #Fecha a conexão\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "    return df, alta, baixa\n",
    "\n",
    "\n",
    "%lprun -f sqlite_func sqlite_func()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segundo Método: MongoDB com pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 101.076 s\n",
      "File: <ipython-input-5-3f557e96a83f>\n",
      "Function: pymongo_func at line 4\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     4                                           def pymongo_func():\n",
      "     5                                               #Conecta com o Mongo\n",
      "     6         1      42430.0  42430.0      0.0      client = MongoClient('localhost', 27017)\n",
      "     7         1        311.0    311.0      0.0      trab2 = client.trab2\n",
      "     8                                           \n",
      "     9                                               #1 Cria tabela vacinas e carrega os dados\n",
      "    10         1        396.0    396.0      0.0      vacs = trab2.vacinas\n",
      "    11      1606    1383817.0    861.7      0.1      for i in vacinas:\n",
      "    12      1606  798313666.0 497082.0     79.0          vacs.insert_many(i.to_pylist())\n",
      "    13                                           \n",
      "    14                                               #2 Cria tabela códigos e carrega os dados\n",
      "    15         1        282.0    282.0      0.0      cods = trab2.codigos\n",
      "    16         1    2405463.0 2405463.0      0.2      cods.insert_many(csv.read_csv('Tabela_codigos.csv').to_pylist())\n",
      "    17                                           \n",
      "    18                                               #3/4 Juntas as tabelas e conta vacinados\n",
      "    19         1  208195880.0 208195880.0     20.6      pipe = vacs.aggregate([\n",
      "    20         1          7.0      7.0      0.0          { \"$group\":{\n",
      "    21         1          3.0      3.0      0.0                  \"_id\": '$estabelecimento_municipio_codigo',\n",
      "    22         1          5.0      5.0      0.0                  \"count\": {\"$sum\": 1}\n",
      "    23                                                   } },\n",
      "    24         1          6.0      6.0      0.0          { \"$lookup\":{\n",
      "    25         1          2.0      2.0      0.0              \"from\": \"codigos\",\n",
      "    26         1          2.0      2.0      0.0              \"localField\": \"_id\",\n",
      "    27         1          2.0      2.0      0.0              'foreignField': 'Cód IBGE',\n",
      "    28         1          3.0      3.0      0.0              'as': 'muni'\n",
      "    29                                                   } },\n",
      "    30         1          9.0      9.0      0.0          { \"$group\":{\n",
      "    31         1          8.0      8.0      0.0                  \"_id\": {'$arrayElemAt': ['$muni.Cód Região de Saúde',0]},\n",
      "    32         1          5.0      5.0      0.0                  \"Nome\": {'$first': '$muni.Nome da Região de Saúde'},\n",
      "    33         1          4.0      4.0      0.0                  \"UF\": {'$first': \"$muni.UF\"},\n",
      "    34         1          3.0      3.0      0.0                  \"count\": {'$sum': '$count'}\n",
      "    35                                                   }},\n",
      "    36         1          6.0      6.0      0.0          {'$sort': {'count': -1}},\n",
      "    37         1          4.0      4.0      0.0          {'$out': 'joined'}\n",
      "    38                                                   ])\n",
      "    39                                           \n",
      "    40                                               #5 Crias as faixas de vacinação\n",
      "    41         1      16289.0  16289.0      0.0      median = [i for i in trab2.joined.find()][math.floor(trab2.joined.estimated_document_count()/2)]['count']\n",
      "    42         1     161512.0 161512.0      0.0      pipe = trab2.joined.aggregate([\n",
      "    43         1          9.0      9.0      0.0                  {\"$project\":{\n",
      "    44         1          3.0      3.0      0.0                          '-id': 1, 'Nome': 1, 'UF': 1, 'count': 1,\n",
      "    45         1         14.0     14.0      0.0                          'faixa' :{ '$cond': { 'if': { '$lte': [ \"$count\", median ] }, 'then': 'Baixa', 'else': 'Alta' }}\n",
      "    46                                                           }},\n",
      "    47         1          5.0      5.0      0.0                  {'$out': 'joined'}\n",
      "    48                                                   ])\n",
      "    49                                           \n",
      "    50                                               #6 Menos Vacinados Alta/Baixa \n",
      "    51         1     202664.0 202664.0      0.0      alta = pd.DataFrame([i for i in trab2.joined.find({'faixa': 'Alta'})][-5:])\n",
      "    52         1      18039.0  18039.0      0.0      baixa = pd.DataFrame([i for i in trab2.joined.find({'faixa': 'Baixa'})][-5:])\n",
      "    53                                               \n",
      "    54                                               #7 Retorna \n",
      "    55         1      15790.0  15790.0      0.0      df = pd.DataFrame([i for i in trab2.joined.find()])\n",
      "    56                                           \n",
      "    57         1          4.0      4.0      0.0      return df,alta,baixa"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import math\n",
    "def pymongo_func():\n",
    "    #Conecta com o Mongo\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    trab2 = client.trab2\n",
    "\n",
    "    #1 Cria tabela vacinas e carrega os dados\n",
    "    vacs = trab2.vacinas\n",
    "    for i in vacinas:\n",
    "        vacs.insert_many(i.to_pylist())\n",
    "\n",
    "    #2 Cria tabela códigos e carrega os dados\n",
    "    cods = trab2.codigos\n",
    "    cods.insert_many(csv.read_csv('Tabela_codigos.csv').to_pylist())\n",
    "\n",
    "    #3/4 Juntas as tabelas e conta vacinados\n",
    "    pipe = vacs.aggregate([\n",
    "        { \"$group\":{\n",
    "                \"_id\": '$estabelecimento_municipio_codigo',\n",
    "                \"count\": {\"$sum\": 1}\n",
    "        } },\n",
    "        { \"$lookup\":{\n",
    "            \"from\": \"codigos\",\n",
    "            \"localField\": \"_id\",\n",
    "            'foreignField': 'Cód IBGE',\n",
    "            'as': 'muni'\n",
    "        } },\n",
    "        { \"$group\":{\n",
    "                \"_id\": {'$arrayElemAt': ['$muni.Cód Região de Saúde',0]},\n",
    "                \"Nome\": {'$first': '$muni.Nome da Região de Saúde'},\n",
    "                \"UF\": {'$first': \"$muni.UF\"},\n",
    "                \"count\": {'$sum': '$count'}\n",
    "        }},\n",
    "        {'$sort': {'count': -1}},\n",
    "        {'$out': 'joined'}\n",
    "        ])\n",
    "\n",
    "    #5 Crias as faixas de vacinação\n",
    "    median = [i for i in trab2.joined.find()][math.floor(trab2.joined.estimated_document_count()/2)]['count']\n",
    "    pipe = trab2.joined.aggregate([\n",
    "                {\"$project\":{\n",
    "                        '-id': 1, 'Nome': 1, 'UF': 1, 'count': 1,\n",
    "                        'faixa' :{ '$cond': { 'if': { '$lte': [ \"$count\", median ] }, 'then': 'Baixa', 'else': 'Alta' }}\n",
    "                }},\n",
    "                {'$out': 'joined'}\n",
    "        ])\n",
    "\n",
    "    #6 Menos Vacinados Alta/Baixa \n",
    "    alta = pd.DataFrame([i for i in trab2.joined.find({'faixa': 'Alta'})][-5:])\n",
    "    baixa = pd.DataFrame([i for i in trab2.joined.find({'faixa': 'Baixa'})][-5:])\n",
    "    \n",
    "    #7 Retorna \n",
    "    df = pd.DataFrame([i for i in trab2.joined.find()])\n",
    "\n",
    "    return df,alta,baixa\n",
    "\n",
    "%lprun -f pymongo_func pymongo_func()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terceiro Método: Spark com pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 40.3304 s\n",
      "File: <ipython-input-6-ffb1830a8d63>\n",
      "Function: spark_func at line 6\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     6                                           def spark_func():\n",
      "     7         1   39575641.0 39575641.0      9.8      spark = SparkSession.builder.appName(\"trab2\").getOrCreate()\n",
      "     8                                           \n",
      "     9         2       7258.0   3629.0      0.0      vacs = spark.read.option(\"delimiter\", \";\")\\\n",
      "    10         1          4.0      4.0      0.0          .option(\"header\", \"true\")\\\n",
      "    11         2       2111.0   1055.5      0.0          .option(\"inferSchema\", \"true\").csv(['dados/'+i for i in os.listdir('dados')])\\\n",
      "    12         1          6.0      6.0      0.0          .select('estabelecimento_uf', 'vacina_descricao_dose', 'estabelecimento_municipio_codigo')\n",
      "    13                                           \n",
      "    14         2       6622.0   3311.0      0.0      cods = spark.read\\\n",
      "    15         1          4.0      4.0      0.0          .option(\"header\", \"true\")\\\n",
      "    16         2         10.0      5.0      0.0          .option(\"inferSchema\", \"true\").csv('Tabela_codigos.csv')\n",
      "    17                                           \n",
      "    18         2     649131.0 324565.5      0.2      joined = vacs.join(cods, vacs.estabelecimento_municipio_codigo == cods['Cód IBGE'], 'left')\\\n",
      "    19         2      17657.0   8828.5      0.0          .groupBy(['Cód Região de Saúde','Nome da Região de Saúde','UF']).count().sort(col('count').desc())\n",
      "    20         1   97104346.0 97104346.0     24.1      s = F.lit(joined.approxQuantile('count',[0.5],0.1)[0])\n",
      "    21         1     145183.0 145183.0      0.0      joined = joined.withColumn('Faixa', when(joined['count'] > s, 'Alta').otherwise('Baixa'))\n",
      "    22                                           \n",
      "    23         1   90865133.0 90865133.0     22.5      alta = joined[joined['Faixa'] == 'Alta'].tail(5)\n",
      "    24         1   87832517.0 87832517.0     21.8      baixa = joined[joined['Faixa'] == 'Baixa'].tail(5)\n",
      "    25         1   87098787.0 87098787.0     21.6      df = joined.toPandas()\n",
      "    26                                           \n",
      "    27         1          4.0      4.0      0.0      return df, alta, baixa"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "def spark_func():\n",
    "    spark = SparkSession.builder.appName(\"trab2\").getOrCreate()\n",
    "\n",
    "    vacs = spark.read.option(\"delimiter\", \";\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferSchema\", \"true\").csv(['dados/'+i for i in os.listdir('dados')])\\\n",
    "        .select('estabelecimento_uf', 'vacina_descricao_dose', 'estabelecimento_municipio_codigo')\n",
    "\n",
    "    cods = spark.read\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferSchema\", \"true\").csv('Tabela_codigos.csv')\n",
    "\n",
    "    joined = vacs.join(cods, vacs.estabelecimento_municipio_codigo == cods['Cód IBGE'], 'left')\\\n",
    "        .groupBy(['Cód Região de Saúde','Nome da Região de Saúde','UF']).count().sort(col('count').desc())\n",
    "    s = F.lit(joined.approxQuantile('count',[0.5],0.1)[0])\n",
    "    joined = joined.withColumn('Faixa', when(joined['count'] > s, 'Alta').otherwise('Baixa'))\n",
    "\n",
    "    alta = joined[joined['Faixa'] == 'Alta'].tail(5)\n",
    "    baixa = joined[joined['Faixa'] == 'Baixa'].tail(5)\n",
    "    df = joined.toPandas()\n",
    "\n",
    "    return df, alta, baixa\n",
    "\n",
    "%lprun -f spark_func spark_func()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quarto Método: Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.0165127 s\n",
      "File: <ipython-input-2-12173ba1b5c5>\n",
      "Function: polars_func at line 3\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     3                                           def polars_func():\n",
      "     4         2        836.0    418.0      0.5      df = pl.scan_csv('dados/*.csv', sep=';', has_header=True).select(['estabelecimento_uf', 'vacina_descricao_dose', 'estabelecimento_municipio_codigo'])\\\n",
      "     5         1       2404.0   2404.0      1.5          .join(pl.scan_csv('Tabela_codigos.csv'), how = 'left', left_on='estabelecimento_municipio_codigo', right_on='Cód IBGE')\\\n",
      "     6         2         54.0     27.0      0.0          .groupby(['Cód Região de Saúde', 'Nome da Região de Saúde', 'UF']).agg(pl.count())\\\n",
      "     7         1        457.0    457.0      0.3          .with_columns((pl.col('count') > pl.col('count').median()).apply(lambda x: 'Alta' if x else 'Baixa').alias('Faixa'))\\\n",
      "     8         1          3.0      3.0      0.0          .sort(by='count', reverse=True)\\\n",
      "     9                                                   .collect()\n",
      "    10                                               \n",
      "    11         1     158676.0 158676.0     96.1      alta = df.filter(pl.col('Faixa') == 'Alta').tail(5)\n",
      "    12         1       2691.0   2691.0      1.6      baixa = df.filter(pl.col('Faixa') == 'Baixa').tail(5)\n",
      "    13                                               \n",
      "    14         1          6.0      6.0      0.0      return df, alta, baixa"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "def polars_func():\n",
    "    df = pl.scan_csv('dados/*.csv', sep=';', has_header=True).select(['estabelecimento_uf', 'vacina_descricao_dose', 'estabelecimento_municipio_codigo'])\\\n",
    "        .join(pl.scan_csv('Tabela_codigos.csv'), how = 'left', left_on='estabelecimento_municipio_codigo', right_on='Cód IBGE')\\\n",
    "        .groupby(['Cód Região de Saúde', 'Nome da Região de Saúde', 'UF']).agg(pl.count())\\\n",
    "        .with_columns((pl.col('count') > pl.col('count').median()).apply(lambda x: 'Alta' if x else 'Baixa').alias('Faixa'))\\\n",
    "        .sort(by='count', reverse=True)\\\n",
    "        .collect()\n",
    "    \n",
    "    alta = df.filter(pl.col('Faixa') == 'Alta').tail(5)\n",
    "    baixa = df.filter(pl.col('Faixa') == 'Baixa').tail(5)\n",
    "    \n",
    "    return df, alta, baixa\n",
    "\n",
    "%lprun -f polars_func polars_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os métodos MongoDB e Spark tiveram tempos bem inconsistentes, às vezes alguns minutos, às vezes durando 6-7 minutos. Acredito que o motivo seja o uso de outros recursos computacionais, como a leitura dos arquivos no HD e a forma que eles reprocessam informações.\n",
    "\n",
    "(parte 1)\n",
    "    Datatable - 12s\n",
    "    Pandas - 16s\n",
    "(parte 2)\n",
    "\n",
    "    SQLite - 92s\n",
    "    MongoDB - 101s\n",
    "    Spark - 40s\n",
    "    Polars - **5.9s**\n",
    "\n",
    "- Todos os métodos tem um gargalo na leitura dos arquivos, pois o HD é lento na leitura.\n",
    "- O Polars foi o mais rápido de todos os métodos testados até agora. Por ele ser lazy, ele consegue otimizar a leitura dos arquivos e o processamento.\n",
    "- Todos os métodos tiveram picos de memória parecidos, na faixa de 2GB.\n",
    "- Diferente os outros métodos, o Spark também utiliza 100% do processador para realizar as operações"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
